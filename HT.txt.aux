\relax 
\pgfsyspdfmark {pgfid1}{7613812}{48094858}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Next Generation Sequencing in Personal Genomics Pipelines}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sequencing of patients with two different sequencing platofrms. F1 score of single callers, which indicates how well a caller is able to find predict true positives (See appendix 5.3 for more details). Figure from Dugas et al., 2016\relax }}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Variant Calling in Personal Genomics Pipelines}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Variant Calling Pileup - Due to noise and errors in sequencing and variant mapping, it is sometimes difficult properly call variants. Figure adapted from CLC Genomics Workbench 9.5, Figure 29.8.\relax }}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Deep Learning in Variant Calling Methodology}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A Neural Network with 1 input layer, 3 hidden layers and 1 output layer. This represents a densely connected neural network, where each node is connected to every node of the preceding and subsequent layers. At each node, linking functions can be defined to apply a mathematical transform to connect the input and output.\relax }}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Bayesian Networks in Gene Prioritisation}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A Sample Bayesian Network for Rain Prediction.\relax }}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Aims and Research Structure}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overall Analysis Structure}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overall Analytical Pipelines - Pipelines were implemented using the Groovy Domain Specific Language, NextFlow\relax }}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Programming and Pipelining tools}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Artificial Datasets}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Alignment and Variant Calling}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Pipeline for simulation of artificial genome for analysis\relax }}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Feature Engineering}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Patient Derived Xenograft Mouse Model Development and Sequencing}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generation of Artificial Datasets}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Number of ground truth mutations (variants) created in each chromosome \relax }}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Mutation rate per base in each chromosome\relax }}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature Engineering}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Feature Engineering Table\relax }}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Variant Callers}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Concordance of callers on simulated dataset, using default settings\relax }}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Table Comparing Methods and Features of Different variant callers.\relax }}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Network Architecture}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Different Designs for Neural Network Architecture\relax }}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Analysis of Different Neural Network Architecture\relax }}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Network Tuning and Optimisation}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Basic Merge Network Structure\relax }}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Analysis of Different Number of Layers On Training Accuracy\relax }}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Optimiser accuracies for training at each epoch. Due to the noise in accuracies, the overall momentum of the dataset, calculated as a sliding window average is shown. The 95\% confidence interval is also shown.\relax }}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Training Accuracies over Each Epoch for Different Learning Rates\relax }}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Effect of Sample Balancing on Prediction Ability \relax }}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Benchmarking of Optimised Network with Mason Datasets}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Overall Comparison of Variant Callers\relax }}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Comparison of Best Variant Callers in terms of Precision, Recall and F1 Score\relax }}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Benchmarking of Network with NA Datasets}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Comparison of Variant Callers\relax }}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Analysis of gene importance using Bayesian Ranking systems}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Final Bayesian Network used in Analysis\relax }}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Table of Functional Annotations obtained from ANNOVAR\relax }}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Validation of Bayesian Network Ranking on PDX dataset}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Top 30 genes from Bayesian Ranking Algorithm\relax }}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Table of Top 5 important genes from Bayesian Ranking\relax }}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces 5 year survival curve of patients with SPRR1A+ and SPRR1A- patients with DLBCL. Source : Zhang et al. (2014), Figure 2.\relax }}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Circos plot of top 300 ranked genes from Bayesian network ranking. In this Circos plot, the outer track indicates the top ranked genes and their positions on the chromosome. The inner track describes the type of mutation that was observed - most mutations were non-synonymous SNVs, with a few stop-gain mutations. The innermost track shows the relative probabilities of each ranked gene.\relax }}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendixes}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural Network Learning}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Example neural networks with nodes and weights\relax }}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Backpropagation of Error Terms\relax }}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Gradient Descent\relax }}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Feature Engineering}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Mathematical and Statistical Tools}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Confusion Matrix\relax }}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Variance captured by first 12 principal components\relax }}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces SMOTE oversampling algorithm\relax }}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Bibilography}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Relevant Code}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}generate\_matrixes.py}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}train\_network.py}{62}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}compute\_bayesian.py}{71}}
\gdef\minted@oldcachelist{,
  default-pyg-prefix.pygstyle,
  default.pygstyle,
  708C9BCB12B5216BBF86DAFDD16ECE411783A10277C0CC29BFFEC5BB6F4B264B.pygtex,
  5E175A629D12D2B8F372883CA9A423BB1783A10277C0CC29BFFEC5BB6F4B264B.pygtex,
  4997910BF66F97E9C5DC9311827F542B1783A10277C0CC29BFFEC5BB6F4B264B.pygtex}
