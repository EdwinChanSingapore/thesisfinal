\relax 
\pgfsyspdfmark {pgfid1}{7613812}{44813021}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Next Generation Sequencing in Personal Genomics Pipelines}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Main Hurdles to Implementation}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Variant Calling in Personal Genomics Pipelines}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Deep Learning in Variant Calling Methodology}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A Neural Network with 1 input layer, 3 hidden layers and 1 output layer. This represents a densely connected neural network, where each node is connected to every node of the preceding and subsequent layers. At each node, linking functions can be defined to apply a mathematical transform to connect the input and output.\relax }}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Bayesian Networks in Gene Prioritisation}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A Sample Bayesian Network for Rain Prediction.\relax }}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Aims and Research Structure}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Artificial Datasets}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Pipeline for simulation of artificial genome for analysis\relax }}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Feature Engineering}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Variant Callers}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table Comparing Methods and Features of Different variant callers.\relax }}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Overall Analysis Structure}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Overall Analytical Pipelines - Pipelines were implemented using the Groovy Domain Specific Language, NextFlow\relax }}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Technologies}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Patient Derived Xenograft Mouse Model Development and Sequencing}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generation of Artificial Datasets}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Number of ground truth mutations (variants) created in each chromosome \relax }}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mutation rate per base in each chromosome\relax }}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Pipeline for simulation of artificial genome for analysis\relax }}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature Engineering}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Feature Engineering Table\relax }}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Variant Callers}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Table Comparing Methods and Features of Different variant callers.\relax }}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Network Architecture}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Different Designs for Neural Network Architecture\relax }}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Analysis of Different Neural Network Architecture\relax }}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Network Tuning and Optimisation}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Basic Merge Network Structure\relax }}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Analysis of Different Number of Layers On Training Accuracy\relax }}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Optimiser accuracies for training at each epoch. Due to the noise in accuracies, the overall momentum of the dataset, calculated as a sliding window average is shown. The 95\% confidence interval is also shown.\relax }}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Training Accuracies over Each Epoch for Different Learning Rates\relax }}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Effect of Sample Balancing on Prediction Ability \relax }}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Benchmarking of Network with Mason Datasets}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Overall Comparison of Variant Callers\relax }}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Comparison of Best Variant Callers in terms of Precision, Recall and F1 Score\relax }}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Benchmarking of Network with NA Datasets}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Comparison of Variant Callers\relax }}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Analysis of gene importance using Bayesian Ranking systems}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Final Bayesian Network used in Analysis\relax }}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Table of Functional Annotations obtained from ANNOVAR\relax }}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Validation of Bayesian Network Ranking on PDX dataset}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Top 30 genes from Bayesian Ranking Algorithm\relax }}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Table of Top 5 important genes from Bayesian Ranking\relax }}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces 5 year survival curve of patients with SPRR1A+ and SPRR1A- patients with DLBCL. Source : Zhang et al. (2014), Figure 2.\relax }}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Circos plot of top 300 ranked genes from Bayesian network ranking\relax }}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendixes}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural Network Learning}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Example neural networks with nodes and weights\relax }}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Backpropagation of Error Terms\relax }}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Gradient Descent\relax }}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Feature Engineering}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Mathematical and Statistical Tools}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Confusion Matrix\relax }}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Variance captured by first 12 principal components\relax }}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces SMOTE oversampling algorithm\relax }}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Bibilography}{48}}
