\contentsline {section}{\numberline {1}Introduction}{2}
\contentsline {subsection}{\numberline {1.1}Next Generation Sequencing (NGS) for Clinical Genomics}{2}
\contentsline {subsection}{\numberline {1.2}Variant Calling of NGS Data}{2}
\contentsline {subsection}{\numberline {1.3}Ensemble Methods for Improving the Accuracy of Variant Calling}{4}
\contentsline {subsection}{\numberline {1.4}Deep Learning for Improving the Accuracy of Variant Calling}{5}
\contentsline {subsection}{\numberline {1.5}Prioritisation of Variants with Bayesian Networks }{7}
\contentsline {subsection}{\numberline {1.6}Aims and Approach}{9}
<<<<<<< HEAD
\contentsline {section}{\numberline {2}Materials and Methods}{10}
\contentsline {subsection}{\numberline {2.1}Overall Analysis Structure}{10}
\contentsline {subsection}{\numberline {2.2}Programming and Pipelining tools}{11}
\contentsline {subsubsection}{\numberline {2.2.1}General Programming Language}{11}
\contentsline {subsubsection}{\numberline {2.2.2}Pipelining}{12}
\contentsline {subsubsection}{\numberline {2.2.3}Deep Learning}{12}
\contentsline {subsubsection}{\numberline {2.2.4}Gene Ranking}{12}
\contentsline {subsection}{\numberline {2.3}Simulated Datasets}{12}
\contentsline {subsection}{\numberline {2.4}Alignment and Variant Calling}{13}
\contentsline {subsection}{\numberline {2.5}Feature Engineering}{13}
\contentsline {subsection}{\numberline {2.6}Patient Derived Xenograft Mouse Model Development and Sequencing}{15}
\contentsline {section}{\numberline {3}Results}{16}
\contentsline {subsection}{\numberline {3.1}Generation of Simulated Datasets}{16}
\contentsline {subsection}{\numberline {3.2}Feature Engineering}{17}
\contentsline {subsection}{\numberline {3.3}Variant Callers}{18}
\contentsline {subsection}{\numberline {3.4}Network Architecture}{19}
\contentsline {subsection}{\numberline {3.5}Network Tuning and Optimisation}{21}
\contentsline {subsubsection}{\numberline {3.5.1}Number of Layers}{22}
\contentsline {subsubsection}{\numberline {3.5.2}Optimiser and Learning Rates}{23}
\contentsline {subsubsection}{\numberline {3.5.3}Sample Balancing}{25}
\contentsline {subsection}{\numberline {3.6}Benchmarking of Optimised Network with Mason Dataset}{26}
\contentsline {subsection}{\numberline {3.7}Benchmarking of Optimised Network with NA Dataset}{28}
\contentsline {subsection}{\numberline {3.8}Analysis of Gene Importance using Bayesian Ranking systems}{30}
\contentsline {subsection}{\numberline {3.9}Validation of Bayesian Network Ranking on PDX dataset}{31}
\contentsline {section}{\numberline {4}Discussion}{35}
\contentsline {subsection}{\numberline {4.1}Comparison of Deep Learning with other Integration Methods}{35}
\contentsline {subsection}{\numberline {4.2}Analysis of Bayesian Network}{37}
\contentsline {subsection}{\numberline {4.3}Future Directions}{38}
\contentsline {section}{\numberline {5}Appendixes}{39}
\contentsline {subsection}{\numberline {5.1}Neural Network Learning}{39}
\contentsline {subsubsection}{\numberline {5.1.1}Feedforward Phase}{39}
\contentsline {subsubsection}{\numberline {5.1.2}Backpropagation Phase}{40}
\contentsline {subsubsection}{\numberline {5.1.3}Cost Function in Gradient Descent}{41}
\contentsline {subsection}{\numberline {5.2}Feature Engineering}{43}
\contentsline {subsubsection}{\numberline {5.2.1}Base Information}{43}
\contentsline {subsubsection}{\numberline {5.2.2}Sequencing Biases and Errors}{44}
\contentsline {subsubsection}{\numberline {5.2.3}Calling and Mapping Qualities}{45}
\contentsline {subsection}{\numberline {5.3}Mathematical and Statistical Tools}{47}
\contentsline {subsubsection}{\numberline {5.3.1}Derivation of F1 Score}{47}
\contentsline {subsubsection}{\numberline {5.3.2}Principal Components Analysis (PCA)}{48}
\contentsline {subsubsection}{\numberline {5.3.3}Synthetic Minority Overrepresentation Technique (SMOTE)}{49}
\contentsline {section}{\numberline {6}Bibilography}{50}
\contentsline {section}{\numberline {7}Relevant Code}{61}
\contentsline {subsection}{\numberline {7.1}generate\_matrixes.py}{61}
\contentsline {subsection}{\numberline {7.2}train\_network.py}{70}
\contentsline {subsection}{\numberline {7.3}compute\_bayesian.py}{79}
=======
\contentsline {section}{\numberline {2}Materials and Methods}{11}
\contentsline {subsection}{\numberline {2.1}Overall Experimental Approach}{11}
\contentsline {subsection}{\numberline {2.2}Implementation of Computational Pipelines}{12}
\contentsline {subsubsection}{\numberline {2.2.1}Workflow Management of Pipelines}{12}
\contentsline {subsubsection}{\numberline {2.2.2}Preprocessing and Analysis}{13}
\contentsline {subsubsection}{\numberline {2.2.3}Implementation of Deep Learning Networks}{13}
\contentsline {subsubsection}{\numberline {2.2.4}Bayesian Network Ranking of Mutations}{13}
\contentsline {subsection}{\numberline {2.3}Generation of Synthetic Dataset}{13}
\contentsline {subsection}{\numberline {2.4}Alignment and Variant Calling of Sequence Reads}{14}
\contentsline {subsection}{\numberline {2.5}Feature Engineering for Deep Learning}{14}
\contentsline {subsection}{\numberline {2.6}Patient Derived Xenograft Mouse Model Development and Sequencing}{16}
\contentsline {section}{\numberline {3}Results}{17}
\contentsline {subsection}{\numberline {3.1}Generation of Artificial Datasets}{17}
\contentsline {subsection}{\numberline {3.2}Feature Engineering}{18}
\contentsline {subsection}{\numberline {3.3}Variant Callers}{19}
\contentsline {subsection}{\numberline {3.4}Network Architecture}{20}
\contentsline {subsection}{\numberline {3.5}Network Tuning and Optimisation}{22}
\contentsline {subsubsection}{\numberline {3.5.1}Number of Layers}{23}
\contentsline {subsubsection}{\numberline {3.5.2}Optimiser and Learning Rates}{25}
\contentsline {subsubsection}{\numberline {3.5.3}Sample Balancing}{26}
\contentsline {subsection}{\numberline {3.6}Benchmarking of Optimised Network with Mason Dataset}{28}
\contentsline {subsection}{\numberline {3.7}Benchmarking of Optimised Network with NA Dataset}{29}
\contentsline {subsection}{\numberline {3.8}Analysis of Gene Importance using Bayesian Ranking systems}{31}
\contentsline {subsection}{\numberline {3.9}Validation of Bayesian Network Ranking on PDX dataset}{32}
\contentsline {section}{\numberline {4}Discussion}{37}
\contentsline {subsection}{\numberline {4.1}Comparison of Deep Learning with other Integration Methods}{37}
\contentsline {subsection}{\numberline {4.2}Analysis of Bayesian Network}{39}
\contentsline {subsection}{\numberline {4.3}Future Directions}{39}
\contentsline {section}{\numberline {5}Appendixes}{40}
\contentsline {subsection}{\numberline {5.1}Neural Network Learning}{40}
\contentsline {subsubsection}{\numberline {5.1.1}Feedforward Phase}{40}
\contentsline {subsubsection}{\numberline {5.1.2}Backpropagation Phase}{41}
\contentsline {subsubsection}{\numberline {5.1.3}Cost Function in Gradient Descent}{42}
\contentsline {subsection}{\numberline {5.2}Feature Engineering}{44}
\contentsline {subsubsection}{\numberline {5.2.1}Base Information}{44}
\contentsline {subsubsection}{\numberline {5.2.2}Sequencing Biases and Errors}{45}
\contentsline {subsubsection}{\numberline {5.2.3}Calling and Mapping Qualities}{46}
\contentsline {subsection}{\numberline {5.3}Mathematical and Statistical Tools}{48}
\contentsline {subsubsection}{\numberline {5.3.1}Derivation of F1 Score}{48}
\contentsline {subsubsection}{\numberline {5.3.2}Principal Components Analysis (PCA)}{49}
\contentsline {subsubsection}{\numberline {5.3.3}Synthetic Minority Overrepresentation Technique (SMOTE)}{50}
\contentsline {section}{\numberline {6}Bibilography}{51}
\contentsline {section}{\numberline {7}Relevant Code}{63}
\contentsline {subsection}{\numberline {7.1}generate\_matrixes.py}{63}
\contentsline {subsection}{\numberline {7.2}train\_network.py}{74}
\contentsline {subsection}{\numberline {7.3}compute\_bayesian.py}{85}
>>>>>>> b6d3c19837f77aef347739cb834beff81a3de066
